# -*- coding: utf-8 -*-
"""Feedback_classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13pQ_TQpgAH8aflTbuEsAjRnoaQRa38zv
"""

# ==============================
# ðŸ“Œ Cell 1: Imports + Stopwords
# ==============================
import re
import difflib

# Load stopwords from file (put stopwords.txt in same directory)
with open("stopwords.txt", "r", encoding="utf-8") as f:
    stopwords = set(word.strip().lower() for word in f.readlines())

# Load positive and negative words for sentiment analysis
with open("positive.txt", "r", encoding="utf-8") as f:
    positive_words = set(word.strip().lower() for word in f.readlines())

with open("negative.txt", "r", encoding="utf-8") as f:
    negative_words = set(word.strip().lower() for word in f.readlines())
    
# ==============================
# ðŸ“Œ Word Variation Handling
# ==============================

def normalize_repeated_chars(word):
    """
    Normalize words with repeated characters like 'goooood' to 'good'
    """
    if not word:
        return word
        
    result = [word[0]]
    for char in word[1:]:
        if char != result[-1]:
            result.append(char)
    
    return ''.join(result)

def is_similar_to_any(word, word_list, threshold=0.8):
    """
    Check if a word is similar to any word in the word_list using fuzzy matching
    """
    # First normalize repeated characters
    normalized_word = normalize_repeated_chars(word)
    
    # Try exact match with normalized word
    if normalized_word in word_list:
        return True
    
    # Try fuzzy matching
    for dict_word in word_list:
        similarity = difflib.SequenceMatcher(None, normalized_word, dict_word).ratio()
        if similarity >= threshold:
            return True
    
    return False

# def preprocess(text: str):
#     """
#     Preprocess text:
#     - Lowercase
#     - Tokenize into words and emojis separately
#     - Remove stopwords
#     """
#     text = text.lower().strip()

#     # Regex: capture words (with @, #, etc.) and emojis separately
#     tokens = re.findall(r"[a-zA-Z0-9@#]+|[\U0001F600-\U0001F64F]|[\U0001F300-\U0001F5FF]", text)

#     # Filter stopwords
#     tokens = [t for t in tokens if t not in stopwords]
#     return tokens

def preprocess(text: str):
    """
    Preprocess text:
    - Lowercase
    - Tokenize into words WITH common censor symbols kept (so 'f***' stays one token)
    - Remove stopwords
    """
    text = text.lower().strip()

    # Words + common censor symbols in the same token; keep emojis too
    tokens = re.findall(
        r"[a-z0-9@#\*\$\%\&\^\_]+|[\U0001F600-\U0001F64F]|[\U0001F300-\U0001F5FF]",
        text
    )

    # Filter stopwords but keep positive and negative sentiment words
    tokens = [t for t in tokens if t in positive_words or t in negative_words or t not in stopwords]
    return tokens

# ==============================
# ðŸ“Œ Cell 3: Trie Data Structure
# ==============================
class TrieNode:
    def __init__(self):
        self.children = {}
        self.is_end_of_word = False


class Trie:
    def __init__(self):
        self.root = TrieNode()

    def insert(self, word: str):
        node = self.root
        for char in word:
            if char not in node.children:
                node.children[char] = TrieNode()
            node = node.children[char]
        node.is_end_of_word = True

    def search_prefix(self, word: str):
        """
        Returns True if any abusive word is a prefix
        of the given token (e.g., 'chut' in 'chutiya').
        """
        node = self.root
        for char in word:
            if char not in node.children:
                return False
            node = node.children[char]
            if node.is_end_of_word:
                return True
        return False

# ==============================
# ðŸ“Œ Cell 4: Build Abusive Trie + Safe Words
# ==============================
abusive_words= [
    # Hindi/Hinglish
    "chut", "chu", "chodu","madar", "behenchod",
    "bhosdike", "randi", "harami", "gand", "lodu","laude","lavde","lauda","loda", "lund",
    "tatti", "gaand", "bhadwe", "bhadwa", "chinal", "kutta", "kuttiya",
    "kamina", "haram","chud","lendi","saala",

    # English
    "fuck","motherfucker", "bullshit", "bastard",
    "slut", "whore", "asshole", "dick", "pussy", "bitch", "cock", "cunt",
    "dildo", "jerk", "wanker", "retard",

    # Short forms / Obfuscations
    "fck", "fuk", "fk", "phuck", "fuq",
    "mc", "bc", "bsdk", "chod", "ch0d",
    "kutti", "kutte", "rndi"
]

safe_words = ["gandhiji", "gandagi", "gandhak"]   # prevents false positives

trie = Trie()
for word in abusive_words:
    trie.insert(word)

# ==============================
# ðŸ“Œ Cell 5: Regex for Obfuscated Words (Dynamic Generation)
# ==============================

OBFUSCATION = r"[*#x@\$%&^!]+"

def create_obfuscation_regex(word):
    """
    Create regex for abusive word allowing obfuscation like:
    - f***, f@ck
    - chutiy@, ch##tiya
    - m@dar, mad@r
    """
    first, last = word[0], word[-1]
    middle = word[1:-1]

    middle_pattern = ""
    for ch in middle:
        # Each char can be itself OR replaced by obfuscation symbols
        middle_pattern += f"(?:{re.escape(ch)}|{OBFUSCATION})+"

    pattern = f"^{re.escape(first)}(?:[\\W_]*{middle_pattern})?[\\W_]*{re.escape(last)}$"
    return re.compile(pattern, re.IGNORECASE)


# Build regex patterns
patterns = [create_obfuscation_regex(w) for w in abusive_words]

# ==============================
# ðŸ“Œ Cell 6: Main Detection Function
# ==============================

def analyze_sentiment(tokens):
    """
    Analyze sentiment of tokens:
    - Count positive and negative words using fuzzy matching
    - Return sentiment (positive, negative, or neutral)
    """
    positive_count = 0
    negative_count = 0
    
    for token in tokens:
        if is_similar_to_any(token, positive_words):
            positive_count += 1
        if is_similar_to_any(token, negative_words):
            negative_count += 1
    
    if positive_count > negative_count:
        return "Positive"
    elif negative_count > positive_count:
        return "Negative"
    else:
        return "Neutral"

def is_abusive(text: str) -> dict:
    tokens = preprocess(text)
    result = {"classification": "", "sentiment": ""}

    if not tokens:   # if only stopwords / empty
        result["classification"] = "Please give meaningful feedback"
        return result

    for token in tokens:
        # Skip safe words
        if token in safe_words:
            continue

        # Check Trie-based abusive detection
        if trie.search_prefix(token):   # âœ… use your trie, not empty regex
            result["classification"] = "Abusive"
            return result

        # Check obfuscation regex patterns
        for pattern in patterns:
            if pattern.fullmatch(token):   # âœ… stricter than search
                result["classification"] = "Abusive"
                return result

        # Check abusive emoji
        if "ðŸ–•" in tokens:
            result["classification"] = "Abusive"
            return result

    # If feedback is clean, analyze sentiment
    result["classification"] = "Clean"
    result["sentiment"] = analyze_sentiment(tokens)
    
    return result
